{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73258ad2-c386-46ca-88d7-ac1757044719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/videograin/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda/envs/videograin/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean SSIM: 0.44842860102653503\n",
      "Frames: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/videograin/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "\n",
    "@torch.no_grad()\n",
    "def video_ssim_torch(path1, path2, batch_size=32, use_cuda=True):\n",
    "    cap1, cap2 = cv2.VideoCapture(path1), cv2.VideoCapture(path2)\n",
    "    device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "    def frame_iter():\n",
    "        while True:\n",
    "            r1, f1 = cap1.read(); r2, f2 = cap2.read()\n",
    "            if not (r1 and r2): break\n",
    "            if f1.shape[:2] != f2.shape[:2]:\n",
    "                f2 = cv2.resize(f2, (f1.shape[1], f1.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "            # BGR->RGB, HWC->CHW, 0~1\n",
    "            f1t = torch.from_numpy(cv2.cvtColor(f1, cv2.COLOR_BGR2RGB)).permute(2,0,1).float()/255.0\n",
    "            f2t = torch.from_numpy(cv2.cvtColor(f2, cv2.COLOR_BGR2RGB)).permute(2,0,1).float()/255.0\n",
    "            yield f1t, f2t\n",
    "\n",
    "    buf1, buf2, all_scores = [], [], []\n",
    "    for f1t, f2t in frame_iter():\n",
    "        buf1.append(f1t); buf2.append(f2t)\n",
    "        if len(buf1) == batch_size:\n",
    "            x = torch.stack(buf1).to(device)  # [B,3,H,W]\n",
    "            y = torch.stack(buf2).to(device)\n",
    "            scores = ssim(x, y, data_range=1.0, reduction='none')  # [B]\n",
    "            all_scores.extend(scores.detach().cpu().tolist())\n",
    "            buf1.clear(); buf2.clear()\n",
    "\n",
    "    # flush\n",
    "    if buf1:\n",
    "        x = torch.stack(buf1).to(device)\n",
    "        y = torch.stack(buf2).to(device)\n",
    "        scores = ssim(x, y, data_range=1.0, reduction='none')\n",
    "        all_scores.extend(scores.detach().cpu().tolist())\n",
    "\n",
    "    cap1.release(); cap2.release()\n",
    "    if len(all_scores) == 0:\n",
    "        return float(\"nan\"), []\n",
    "    return float(torch.tensor(all_scores).mean()), all_scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mean_ssim, curve = video_ssim_torch(\"./left_iron_right_spider.mp4\", \"after.mp4\", batch_size=16, use_cuda=True)\n",
    "    print(\"Mean SSIM:\", mean_ssim)\n",
    "    print(\"Frames:\", len(curve))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff34953-9f23-4b4a-ad97-33685d9ce729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean SSIM (RGB): 0.43689283121385314 Frames: 16\n",
      "Mean SSIM (Y):   0.4990113087644435 Frames: 16\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ---- 你的函式：保持原樣（只要確保傳入是 RGB） ----\n",
    "def ssim(img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "    try:\n",
    "        from skimage.metrics import structural_similarity as ssim_fn\n",
    "        s, _ = ssim_fn(img1, img2, channel_axis=2, full=True)\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        def _to_gray(x):\n",
    "            return cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "        y1 = _to_gray(img1); y2 = _to_gray(img2)\n",
    "        C1 = (0.01 * 255) ** 2\n",
    "        C2 = (0.03 * 255) ** 2\n",
    "        mu1 = cv2.GaussianBlur(y1, (11, 11), 1.5)\n",
    "        mu2 = cv2.GaussianBlur(y2, (11, 11), 1.5)\n",
    "        mu1_sq = mu1 * mu1\n",
    "        mu2_sq = mu2 * mu2\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        sigma1_sq = cv2.GaussianBlur(y1 * y1, (11, 11), 1.5) - mu1_sq\n",
    "        sigma2_sq = cv2.GaussianBlur(y2 * y2, (11, 11), 1.5) - mu2_sq\n",
    "        sigma12 = cv2.GaussianBlur(y1 * y2, (11, 11), 1.5) - mu1_mu2\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return float(ssim_map.mean())\n",
    "\n",
    "# ---- 影片版：逐幀計算 + 平均 ----\n",
    "def video_ssim(\n",
    "    path_ref: str,\n",
    "    path_cmp: str,\n",
    "    mode: str = \"rgb\",          # \"rgb\" 或 \"y\"（亮度通道）\n",
    "    frame_stride: int = 1,      # 每隔幀抽樣（>1 可加速）\n",
    "    max_frames: int = None,     # 最多計算幾幀（None=全片）\n",
    "    resize_to_ref: bool = True  # 將第二支影片 resize 到第一支尺寸\n",
    ") -> Tuple[float, List[float]]:\n",
    "    \"\"\"\n",
    "    回傳 (mean_ssim, per_frame_scores)\n",
    "    \"\"\"\n",
    "    cap1, cap2 = cv2.VideoCapture(path_ref), cv2.VideoCapture(path_cmp)\n",
    "    assert cap1.isOpened() and cap2.isOpened(), \"無法開啟影片\"\n",
    "\n",
    "    scores: List[float] = []\n",
    "    idx = 0\n",
    "\n",
    "    # 灰階(Y)專用：避免你的 ssim() 因 channel_axis=2 對灰階報錯，這裡直接用 skimage 灰階路徑\n",
    "    from skimage.metrics import structural_similarity as ssim_gray_fn\n",
    "\n",
    "    while True:\n",
    "        r1, f1_bgr = cap1.read()\n",
    "        r2, f2_bgr = cap2.read()\n",
    "        if not (r1 and r2):\n",
    "            break  # 任一方結束就停（對齊部分比較）\n",
    "\n",
    "        # 抽樣\n",
    "        if frame_stride > 1 and (idx % frame_stride != 0):\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        # 尺寸對齊\n",
    "        if resize_to_ref and (f1_bgr.shape[:2] != f2_bgr.shape[:2]):\n",
    "            f2_bgr = cv2.resize(f2_bgr, (f1_bgr.shape[1], f1_bgr.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if mode == \"rgb\":\n",
    "            # BGR -> RGB，再丟進你現有的 ssim()\n",
    "            f1 = cv2.cvtColor(f1_bgr, cv2.COLOR_BGR2RGB)\n",
    "            f2 = cv2.cvtColor(f2_bgr, cv2.COLOR_BGR2RGB)\n",
    "            score = ssim(f1, f2)\n",
    "        elif mode == \"y\":\n",
    "            # 只算亮度（Y 通道，BT.601），用 skimage 灰階 SSIM（data_range=255, channel_axis=None）\n",
    "            y1 = cv2.cvtColor(f1_bgr, cv2.COLOR_BGR2YCrCb)[..., 0]\n",
    "            y2 = cv2.cvtColor(f2_bgr, cv2.COLOR_BGR2YCrCb)[..., 0]\n",
    "            score = float(ssim_gray_fn(y1, y2, data_range=255, full=False))  # 灰階不需要 channel_axis\n",
    "        else:\n",
    "            raise ValueError(\"mode 只能是 'rgb' 或 'y'\")\n",
    "\n",
    "        scores.append(score)\n",
    "        idx += 1\n",
    "\n",
    "        if (max_frames is not None) and (len(scores) >= max_frames):\n",
    "              \n",
    "\n",
    "    cap1.release(); cap2.release()\n",
    "\n",
    "    mean_ssim = float(np.mean(scores)) if scores else float(\"nan\")\n",
    "    return mean_ssim, scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mean_rgb, seq_rgb = video_ssim(\"./left_iron_right_spider.mp4\", \"after.mp4\", mode=\"rgb\", frame_stride=1)\n",
    "    print(\"Mean SSIM (RGB):\", mean_rgb, \"Frames:\", len(seq_rgb))\n",
    "\n",
    "    mean_y, seq_y = video_ssim(\"./left_iron_right_spider.mp4\", \"after.mp4\", mode=\"y\", frame_stride=1)\n",
    "    print(\"Mean SSIM (Y):  \", mean_y, \"Frames:\", len(seq_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f21268-4795-4ab8-8f66-09be1a56ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /root/miniconda/envs/videograin/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Frame 0: LPIPS = 0.51244056224823\n",
      "Frame 1: LPIPS = 0.4972872734069824\n",
      "Frame 2: LPIPS = 0.4989817440509796\n",
      "Frame 3: LPIPS = 0.5041841864585876\n",
      "Frame 4: LPIPS = 0.4837638735771179\n",
      "Frame 5: LPIPS = 0.4780412018299103\n",
      "Frame 6: LPIPS = 0.4992072582244873\n",
      "Frame 7: LPIPS = 0.48317766189575195\n",
      "Frame 8: LPIPS = 0.4920675456523895\n",
      "Frame 9: LPIPS = 0.503842294216156\n",
      "Frame 10: LPIPS = 0.49581634998321533\n",
      "Frame 11: LPIPS = 0.49921563267707825\n",
      "Frame 12: LPIPS = 0.4995573163032532\n",
      "Frame 13: LPIPS = 0.5179522037506104\n",
      "Frame 14: LPIPS = 0.5016171932220459\n",
      "Frame 15: LPIPS = 0.4907822012901306\n",
      "\n",
      "=================================\n",
      "Average LPIPS score: 0.4973709061741829\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import lpips\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# LPIPS model\n",
    "loss_fn = lpips.LPIPS(net='alex')\n",
    "\n",
    "# Image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Convert OpenCV frame to LPIPS tensor\"\"\"\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(frame)\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "def read_video_frames(video_path):\n",
    "    \"\"\"Load all frames from video and return as list\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# === Main comparison ===\n",
    "\n",
    "video1 = \"./left_iron_right_spider.mp4\"\n",
    "video2 = \"./after.mp4\"\n",
    "\n",
    "frames1 = read_video_frames(video1)\n",
    "frames2 = read_video_frames(video2)\n",
    "\n",
    "# 確保兩支影片幀數一致（取最短）\n",
    "n_frames = min(len(frames1), len(frames2))\n",
    "\n",
    "lpips_scores = []\n",
    "\n",
    "for i in range(n_frames):\n",
    "    f1 = preprocess_frame(frames1[i])\n",
    "    f2 = preprocess_frame(frames2[i])\n",
    "\n",
    "    score = loss_fn(f1, f2).item()\n",
    "    lpips_scores.append(score)\n",
    "\n",
    "    print(f\"Frame {i}: LPIPS = {score}\")\n",
    "\n",
    "avg_lpips = np.mean(lpips_scores)\n",
    "\n",
    "print(\"\\n=================================\")\n",
    "print(\"Average LPIPS score:\", avg_lpips)\n",
    "print(\"=================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4095e29-4c39-4ba9-a118-9575952ce5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358687a-3f6f-4509-8577-c2ee5eebb968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videograin",
   "language": "python",
   "name": "videograin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
